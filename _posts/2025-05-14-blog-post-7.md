---
title: 'SMTD_Original_Handout'
date: 2025-05-14
permalink: /posts/2025/05/blog-post-7/
tags:
  - Paper Handout
  - Code
  - Filter
---

STMD2008_生物似然






---
# 滤波
<div style="text-align: center;">
  <img src='/images/STMD2008/2008STMD资料补充1.png'>
  <img src='/images/STMD2008/2008STMD资料补充2.png'>
  <p>补充资料</p>
</div>




---
# Code

试图完全复现2008的那篇文章但是失败
```python
import numpy as np

%matplotlib tk
class STMD():
    def __init__(self,video_size,dt,params=None):
        H,W=video_size
        self.dt=dt
        params = {
                'Inhibition_scaler1':8,
                'Inhibition_scaler2':24
            } if  params is None else params
        

        self.gauss_kernel=self.gaussian_kernel(size=3, sigma=1.0)
        self.Inhibi_kernel_LMC=self.Inhibition_kernel(size=3,scaler=params['Inhibition_scaler1'])
        self.Inhibi_kernel_RTC=self.Inhibition_kernel(size=3,scaler=params['Inhibition_scaler2'])
        #

        #photo
        self.LPF1output_cache=np.zeros((2,H,W))
        self.LPF_lipetz_output_cache=np.zeros((2,H,W))
        self.lipetz_output_cache=np.zeros((2,H,W))
        self.LPF2output_cache=np.zeros((2,H,W))
        #LMC
        self.RHPF1output_cache=np.zeros((2,H,W))
        self.LPF3output_cache=np.zeros((2,H,W))
        self.LMCoutput_cache=np.zeros((2,H,W))
        #RTC
        self.HPF3output_cache=np.zeros((2,H,W))
        self.ON_cache=np.zeros((2,H,W))
        self.OFF_cache=np.zeros((2,H,W))
        self.FDSRoutput_cache_ON=np.zeros((2,H,W))
        self.FDSRoutput_cache_OFF=np.zeros((2,H,W))
        self.LP4output_cache_OFF=np.zeros((2,H,W))
        self.LP4output_cache_ON=np.zeros((2,H,W))

        self.RTC_Inibit_ON_cache=np.zeros((2,H,W))
        self.RTC_Inibit_OFF_cache=np.zeros((2,H,W))

        self.RTC_Final_ON_cache=np.zeros((2,H,W))
        self.RTC_Final_OFF_cache=np.zeros((2,H,W))
        self.LPF5output_cache=np.zeros((2,H,W))
        self.RTC_output_cache=np.zeros((2,H,W))

        #STMD
        self.STMD_output_cache=np.zeros((2,H,W))
    @staticmethod
    def gaussian_kernel(size=3, sigma=1.0):
        ax = np.arange(-size // 2 + 1., size // 2 + 1., dtype=np.float64)
        xx, yy = np.meshgrid(ax, ax)
        kernel = np.exp(-(xx**2 + yy**2) / (2. * sigma**2))
        return kernel / np.sum(kernel)
    
    @staticmethod
    def Inhibition_kernel(size=3, scaler=1.0):
        #[[1,1,1],[1,0,1],[1,1,1]]
        kernel = np.ones((size, size), dtype=np.float64)
        kernel[1,1]=0
        return kernel *1/8* scaler
    
        
    #半波整流
    @staticmethod
    def half_wave_rectifier(x):
        return np.maximum(x, 0)

    def LPF1(self,X):
        """
        X:[H,W]
        Kernel:[h,w]=[3,3]or=[5,5]or...
        """
        return self.conv2d(X,self.gauss_kernel)

    def lipetz(self,x,x_o,u=0.7):
        """
        x_cache:[2,H,W]#y_cache=[x(t-dt),x(t)]
        #tau:s秒

        return [H,W]
        """

        return x**u/(x**u+x_o**u+1e-12)#防止/0
    
    def conv2d(self,A, Kernel):
        """
        对二维矩阵 A 进行卷积操作，使用零填充保持输出维度不变
        参数:
            A (np.array): 输入的二维矩阵，形状为 [H, W]
            Kernel (np.array): 卷积核，形状为 [h, w]，h 和 w 必须为奇数
        返回:
            np.array: 卷积结果，形状与 A 相同
        """
        H, W = A.shape
        h, w = Kernel.shape
        assert h % 2 == 1 and w % 2 == 1, "Kernel 的尺寸必须为奇数"
        
        # 计算需要填充的尺寸
        pad_h = (h - 1) // 2
        pad_w = (w - 1) // 2
        # 对输入矩阵进行零填充
        A_padded = np.pad(A, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant')
        # 初始化输出矩阵
        output = np.zeros_like(A)
        # 遍历每个像素位置进行卷积
        for i in range(H):
            for j in range(W):
                # 提取与 Kernel 对应的区域
                region = A_padded[i:i+h, j:j+w]
                # 计算点乘后求和
                output[i, j] = np.sum(region * Kernel)
        return output
    

    def R_HPF1(self,x_cache,y_cache,dt,tau=0.04):
        """
        x_cache:[2,H,W]#x_cache=[x(t-dt),x(t)]
        y_cache:[H,W]#y_cache=y(t-dt)
        #tau:s秒
        """
        a0=(tau+0.1*dt)/(tau+dt)
        a1=-tau/(tau+dt)
        b1=tau/(tau+dt)
        return a0*x_cache[1]+a1*x_cache[0]+b1*y_cache[0]

    


    def FDSR(self,x_cache,y_cache,dt,tau1=0.001,tau2=0.1):
        """
        x_cache:[2,H,W]#x_cache=[x(t-dt),x(t)]
        y_cache:[H,W]#y_cache=y(t-dt)
        #tau:s秒
        """

        delta=x_cache[1]-y_cache
        # 生成 tau 矩阵
        tau_matrix = np.where(delta >= 0, tau1, tau2)

        return y_cache+dt*(x_cache[1]-y_cache)/tau_matrix
    def LPF(self,dt,tau,x_cache,y_cache):
        """
        x_cache:[2,H,W]#x_cache=[x(t-dt),x(t)]
        y_cache:[2,H,W]#y_cache=y(t-dt)
        """
        a,b=dt/(tau+dt),tau/(tau+dt)
        return a*x_cache[-1]+b*y_cache

    def HPF(self,x_cache,y_cache,dt,tau=0.04):
        """
        x_cache:[2,H,W]#x_cache=[x(t-dt),x(t)]
        y_cache:[H,W]#y_cache=y(t-dt)
        #tau:s秒
        """
        a=tau/(tau+dt)
        return a*(x_cache[1]-x_cache[0]+y_cache[0])

    def LMC_Inibit(self,C,S):
        return C-self.conv2d(S,self.Inhibi_kernel_LMC)

    def RTC_Inibit(self,C,S):
        return C-self.conv2d(S,self.Inhibi_kernel_RTC)

    def _photoreceptor(self,frame):
        """
        frame=[H,W]
        """
        self.LPF1output_cache[0]=self.LPF1output_cache[-1].copy()
        self.LPF1output_cache[-1]=self.LPF1(frame)

        self.LPF_lipetz_output_cache[0]=self.LPF_lipetz_output_cache[-1].copy()
        self.LPF_lipetz_output_cache[-1]=self.LPF(dt=self.dt,tau=0.75,
                                           x_cache=self.lipetz_output_cache,
                                           y_cache=self.LPF1output_cache[0])

        self.lipetz_output_cache[0]=self.lipetz_output_cache[-1].copy()
        self.lipetz_output_cache[-1]=self.lipetz(self.LPF1output_cache[-1],self.LPF_lipetz_output_cache[-1])
        
        self.LPF2output_cache[0]=self.LPF2output_cache[-1].copy()
        self.LPF2output_cache[-1]=self.LPF(dt=self.dt,tau=0.0025,
                                           x_cache=self.lipetz_output_cache,
                                           y_cache=self.LPF2output_cache[0])
    def _LMC(self):
        self.RHPF1output_cache[0]=self.RHPF1output_cache[-1].copy()
        self.RHPF1output_cache[-1]=self.R_HPF1(self.LPF2output_cache,
                                               self.RHPF1output_cache[-1],
                                               self.dt,tau=0.04)
        
        self.LPF3output_cache[0]=self.LPF3output_cache[-1].copy()
        self.LPF3output_cache[-1]=self.LPF(dt=self.dt,tau=0.002,
                                           x_cache=self.RHPF1output_cache,
                                           y_cache=self.LPF3output_cache[0])
        
        self.LMCoutput_cache[0]=self.LMCoutput_cache[-1].copy()
        # self.LMCoutput_cache[-1]=-self.LMC_Inibit(self.RHPF1output_cache[-1],
        #                                      self.LPF3output_cache[-1])
        self.LMCoutput_cache[-1]=self.RHPF1output_cache[-1]


       
    
    def _RTC(self):
        self.HPF3output_cache[0]=self.HPF3output_cache[-1].copy()
        self.HPF3output_cache[1]=self.HPF(self.LMCoutput_cache,
                                          self.HPF3output_cache[0],
                                          self.dt,tau=0.04)
        
        self.ON_cache[0]=self.ON_cache[-1].copy()
        self.ON_cache[1]=self.half_wave_rectifier(self.HPF3output_cache[-1])
        self.OFF_cache[0]=self.OFF_cache[-1].copy()
        self.OFF_cache[1]=self.half_wave_rectifier(-self.HPF3output_cache[-1])

        # FDSR
        self.FDSRoutput_cache_ON[0]=self.FDSRoutput_cache_ON[-1].copy()
        self.FDSRoutput_cache_ON[1]=self.FDSR(self.ON_cache,
                                               self.FDSRoutput_cache_ON[-1],
                                               self.dt,tau1=0.001,tau2=0.1)
        self.FDSRoutput_cache_OFF[0]=self.FDSRoutput_cache_OFF[-1].copy()
        self.FDSRoutput_cache_OFF[1]=self.FDSR(self.OFF_cache,
                                               self.FDSRoutput_cache_OFF[-1],
                                               self.dt,tau1=0.001,tau2=0.1)
        
        # LPF4 INH
        self.LP4output_cache_OFF[0]=self.LP4output_cache_OFF[-1].copy()
        self.LP4output_cache_OFF[1]=self.LPF(dt=self.dt,tau=0.004,
                                           x_cache=self.OFF_cache,
                                           y_cache=self.LP4output_cache_OFF[0])
        self.LP4output_cache_ON[0]=self.LP4output_cache_ON[-1].copy()
        self.LP4output_cache_ON[1]=self.LPF(dt=self.dt,tau=0.004,
                                           x_cache=self.ON_cache,
                                           y_cache=self.LP4output_cache_ON[0])


        #侧抑制
        self.RTC_Inibit_ON_cache[0]=self.RTC_Inibit_ON_cache[-1].copy()
        self.RTC_Inibit_ON_cache[-1]=self.RTC_Inibit(self.FDSRoutput_cache_ON[-1],
                                                      self.LP4output_cache_ON[-1])
        self.RTC_Inibit_OFF_cache[0]=self.RTC_Inibit_OFF_cache[-1].copy()
        self.RTC_Inibit_OFF_cache[-1]=self.RTC_Inibit(self.FDSRoutput_cache_OFF[-1],
                                                      self.LP4output_cache_OFF[-1])
        
        #HW
        self.RTC_Final_ON_cache[0]=self.RTC_Final_ON_cache[-1].copy()
        self.RTC_Final_ON_cache[-1]=self.half_wave_rectifier(self.RTC_Inibit_ON_cache[-1])
        self.RTC_Final_OFF_cache[0]=self.RTC_Final_OFF_cache[-1].copy()
        self.RTC_Final_OFF_cache[-1]=self.half_wave_rectifier(self.RTC_Inibit_OFF_cache[-1])

        #LPF5
        self.LPF5output_cache[0]=self.LPF5output_cache[-1].copy()
        self.LPF5output_cache[-1]=self.LPF(dt=self.dt,tau=0.025,
                                           x_cache=self.RTC_Final_OFF_cache,
                                           y_cache=self.LPF5output_cache[0])
        #sum:RTC output
        self.RTC_output_cache[-1]=self.RTC_Final_ON_cache[-1]+self.LPF5output_cache[-1]

    def _STMD(self):
        self.STMD_output_cache[0]=self.STMD_output_cache[-1].copy()
        self.STMD_output_cache[-1]=self.RTC_Final_ON_cache[-1]*self.LPF5output_cache[-1]

    def forward(self,frame):
        self._photoreceptor(frame)
        self._LMC()
        self._RTC()
        self._STMD()
        
import numpy as np
from tqdm import tqdm
#matrix gernerator----------------------------------------------------------------
# 视频参数
W, H = 16, 16
deltaI=20
model_interval=0.001 #1ms
interval1=0.03
interval2=0.01

# 初始化灰度帧数组 [T, H, W]
gray_frames = np.zeros((600, H, W), dtype=np.float64)

###########
# 逐帧填充灰度值
for i in range(300):

    gray_frames[i, :, :] = (i//30)*deltaI  # 整个画面填充该灰度值

for i in range(300, 600):
    gray_frames[i, :, :] = -((i-300)//30)*deltaI+200  # 整个画面填充该灰度值



#print(gray_frames[31],gray_frames[61],gray_frames[299],gray_frames[300],gray_frames[331],gray_frames[599])#debug


#test ----------------------------------------------------------------
video_size=(H,W)
dt=model_interval
RTC_output=np.zeros((600,H,W))
LMC_output=np.zeros((600,H,W))
Lipetz_output=np.zeros((600,H,W))
LPF2_output=np.zeros((600,H,W))

model=STMD(video_size,dt)
for i in tqdm(range(600),desc='processing frame'):
    frame=gray_frames[i]
    model.forward(frame)
    Lipetz_output[i]=model.lipetz_output_cache[-1]
    LPF2_output[i]=model.LPF2output_cache[-1]
    LMC_output[i]=model.LMCoutput_cache[-1]
    RTC_output[i]=model.RTC_output_cache[-1]

#plot--------------------------------------------------------------------------
import matplotlib.pyplot as plt

# 生成时间轴（单位：秒）
time_points = np.arange(gray_frames.shape[0]) * model_interval  # 每帧间隔1ms

# 提取中心点 (5,5) 的灰度值变化
center_gray = gray_frames[:, 5, 5]
center_RTC=RTC_output[:,5,5]
center_LMC=LMC_output[:,5,5]
center_Lipetz=Lipetz_output[:,5,5]
center_LPF2=LPF2_output[:,5,5]


# 创建画布和第一个纵坐标轴（左侧）
fig, ax1 = plt.subplots(figsize=(10, 5))

# 绘制第一条曲线（左侧轴）
ax1.plot(time_points, center_gray, color='navy', label='Gray Value @ (5,5)')
ax1.set_xlabel('Time (s)')
ax1.set_ylabel('Gray Value', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')
  # 固定左侧轴范围

# 创建第二个纵坐标轴（右侧）
ax2 = ax1.twinx()

# 绘制第二条曲线（右侧轴）
ax2.plot(time_points, center_RTC, color='black', label='RTC @ (5,5)')
ax2.set_ylabel('RTC', color='red')
ax2.tick_params(axis='y', labelcolor='red')

# # 绘制第三条曲线（右侧轴）
# ax2.plot(time_points, center_LMC, color='blue', label='LMC @ (5,5)')
# 绘制第四条曲线（右侧轴）
ax2.plot(time_points, center_Lipetz, color='red', label='Lipetz @ (5,5)')
ax2.plot(time_points, center_LPF2, color='green', label='LPF2 @ (5,5)')

# 合并图例
lines1, labels1 = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

# 显示图形
plt.tight_layout()
plt.show()

```


<div style="text-align: center;">
  <img src='/images/Quasi-Newton_Method/quadratic_Figure_1.png'>
  <p>复刻失败</p>
</div>


DIY复刻
---
```python
import torch
import torch.nn as nn
import numpy as np
import math as m
from tqdm import tqdm

#绘图用
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.animation as animation
from matplotlib.animation import FuncAnimation
import torch.nn.functional as F
```
```python
import torch
from torchvision.io import read_video
from torchvision.transforms.functional import rgb_to_grayscale

def video2tensor(video_path):#->torch.Tensor(float64):
    """
    读取视频并转换为张量[B, C, T, H, W]
    这种读取方法与matlab读取到的会有一点点数值上的偏差比如左上角的像素matlab读取的251，这里读的是250
    """
    # 读取视频（输出[T,C,H,W]）
    video_tensor, audio_tensor, info = read_video(
        video_path,  # 视频路径
        output_format="TCHW"  # 原始形状 [T,3,H,W]
    )

    # 转换为灰度
    video_tensor = rgb_to_grayscale(video_tensor, num_output_channels=1)  # 输出 [T,1,H,W]
    video_tensor=video_tensor.unsqueeze_(0).permute(0, 2, 1, 3, 4)
    #print(video_tensor.shape)
    return torch.tensor(video_tensor, dtype=torch.float64)#[B=1,C=1,T,H,W]
```
```python
# 设置图形在新窗口中显示
%matplotlib tk
class STMD():
    def __init__(self,video_size,conv_params):
        """
        video_size=[H, W]
        video_tensor: [B, C, T, H, W]
        conv_params:dict:例子
            conv_params = {
                'GammaConv3d': {'size': 20, 'tau': 1.0, 'n': 50},
                'GaussConv2d': {'size': 15, 'tau': 0.5, 'n': 40}
            }
        """
        self.conv_params=conv_params
        #for Retina
        self.GaussConv2d_1=self.Gauss_Conv2d_Generate(**conv_params['GaussConv2d_1'])

        #for Lamina
        self.GammaConv3d_1=self.Gamma_Conv3d_Generate(**conv_params['GammaConv3d_1'])
        self.GammaConv3d_2=self.Gamma_Conv3d_Generate(**conv_params['GammaConv3d_2'])
        #for medulla
        self.GammaConv3d_3=self.Gamma_Conv3d_Generate(**conv_params['GammaConv3d_3'])
        #for lobula
        self.GaussConv2d_2=self.Gauss_Conv2d_Generate(Gauss_kernel=
                                                      (self.gaussian_kernel(**conv_params['GaussConv2d_2'])-
                                                      self.gaussian_kernel(**conv_params['GaussConv2d_3']))
                                                      )
        self.poolingConv2d=self.Gauss_Conv2d_Generate(Gauss_kernel=self.pooling_kernel(**conv_params['PoolingConv2d_1']))

        #注意这些cache的更新:新的在后面，旧的在前面，因此新frame从cache的尾巴出栈,最旧的从头出栈
        self.RetinaOutput_cache = torch.zeros([20,video_size[0],video_size[1]], dtype=torch.float64)#[20,W,H]
        #若需要延时超过20ms，即缓存需要缓存更多过去则需要修改

        self.LaminaOutput = torch.zeros(video_size, dtype=torch.float64)#[W,H]

        self.OFF_cache=torch.zeros([20,video_size[0],video_size[1]], dtype=torch.float64)#[20,W,H]
        self.MedullaOutput1_ON = torch.zeros(video_size, dtype=torch.float64)
        self.MedullaOutput2_OFFDELAY = torch.zeros(video_size, dtype=torch.float64)

        self.LobulaOutput = torch.zeros(video_size, dtype=torch.float64)

        #
        self.tempoutput11=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput12=torch.zeros(video_size, dtype=torch.float64)

        self.tempoutput=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput2=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput3=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput4=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput5=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput6=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput7=torch.zeros(video_size, dtype=torch.float64)
        self.tempoutput8=torch.zeros(video_size, dtype=torch.float64)
        self.count=0
        self.k=0

        
    @staticmethod#不加静态方法似乎会传入self,导致调用该函数时报错说传入了多了1个参数
    def gamma_kernel(size,tau=1.0,n=50):
        #[1, 1, size, 1, 1]
        tensor = torch.arange(1, size + 1, dtype=torch.float64)
        GammaKernel=((n*tensor)**n)*torch.exp(-n*tensor/tau)/(tau**(n+1)*m.factorial(n-1))
        return GammaKernel.unsqueeze(-1).unsqueeze(-1).unsqueeze(0).unsqueeze(0)    

    def Gamma_Conv3d_Generate(self,size=20,tau=1.0,n=50):
        """
        fomulate self.GammaConv3d
        """
        # 假设视频张量的形状为 [T,W, H]
        # 定义 3D 卷积层，使用固定的时间卷积核
        conv3d = nn.Conv3d(in_channels=1, out_channels=1, kernel_size=(size, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0),bias=False)

        # 设置卷积层的权重为固定卷积核
        with torch.no_grad():
            temp=torch.flip(self.gamma_kernel(size,tau,n),dims=[2])
            conv3d.weight.data = torch.flip(self.gamma_kernel(size,tau,n),dims=[2])#[1, 1, size, 1, 1]
            conv3d.weight.requires_grad = False  # 冻结权重

        # 应用 3D 卷积
        #[B,C,T,W, H]
        #([1, 1, 20, 128, 128])-->([1, 1, 1, 128, 128])
        return conv3d
    
    def Gamma_Conv3d_forward(self,input,conv):
        # """
        # [B =1, C=1, T=size, H, W]-->[B, C, T=1, H, W]
        # """
        """
        [T=20, H, W]-->[B =1, C=1, T=size, H, W]-->[B, C, T=1, H, W]-->[B, C, T=1, H, W]-->[H, W]
        """
        input = input.unsqueeze(0).unsqueeze(0)  # [1, 1, 20, 128, 128]
        output = conv(input)  # 输出形状为 [1, 1, 1, 128, 128]
        output = output.squeeze(0).squeeze(0).squeeze(0)  # [128, 128]
        return output
    
    def Gauss_Conv2d_Generate(self,sigma=1.0,size=3,Gauss_kernel=None):
        """
        [B , C, T, H, W]-> [B * T, C, H, W]->[B, C, T, H, W]
        """
        # 创建高斯核
        gauss_kernel = self.gaussian_kernel(size, sigma) if Gauss_kernel is None else Gauss_kernel
        gauss_kernel = gauss_kernel.reshape((1, 1, size, size))  # 调整形状(增加前两维)以适应卷积层
        gauss_kernel = torch.tensor(gauss_kernel, dtype=torch.float64)

        # 创建卷积层
        conv = nn.Conv2d(1, 1, kernel_size=size, padding=1, bias=False)#nn.conv2d的输入是[B,C,H,W]
        conv.weight.data = gauss_kernel
        conv.weight.requires_grad = False
        return conv

    def Gauss_Conv2d_forward(self, input,conv):
        # """
        # 此函数用于修改input维度以适配conv的输入要求，并在conv后重新修正input维度
        # [B , C, T, H, W]-> [B * T, C, H, W]->[B, C, T, H, W]
        # """
        # B, C, T, H, W = input.shape  # 获取输入张量的形状
        # reshaped_input = input.reshape(B * T, C, H, W)
        # output = conv(reshaped_input)
        # output = output.reshape(B, T, C, H, W).permute(0, 2, 1, 3, 4)
        """
        [H, W]-> [1,1,H, W]->CONV->[1,1,H,W]->[H, W]
        """

        return conv(input.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0)  # [H, W]

    def Log_Pooling_Conv2d_Forward(self,input,conv):
        """
        [H, W]-> [1,1,H, W]->CONV->[1,1,H,W]->[H, W]
        """
        eps = 1e-6
        input = torch.log(torch.abs(input)+eps)
        return self.Gauss_Conv2d_forward(input,conv)

    # 定义高斯核函数
    @staticmethod
    def gaussian_kernel(size=3, sigma=1.0):
        ax = np.arange(-size // 2 + 1., size // 2 + 1., dtype=np.float64)
        xx, yy = np.meshgrid(ax, ax)
        kernel = np.exp(-(xx**2 + yy**2) / (2. * sigma**2))
        return kernel / np.sum(kernel)
    
    @staticmethod
    def pooling_kernel(size=3, scaler=1.0):
        # 生成3x3全1的池化核（类型保持与gamma_kernel一致）
        kernel = np.ones((size, size), dtype=np.float64)
        return kernel * scaler

    #半波整流
    @staticmethod
    def half_wave_rectifier(x):
        return np.maximum(x, 0)

    def Retina(self,frame):
        #i:i+1的方式可以让shape不变，如果用i的话为少掉这个维度
        # output1=self.Gauss_Conv2d_forward(self.video_tensor[:,:,i:i+1,:,:],self.GaussConv2d_1)
        # self.RetinaOutput[:,:,i,:,:]=output1

        output1=self.Gauss_Conv2d_forward(frame,self.GaussConv2d_1)
        self.RetinaOutput_cache[:-1,:,:]=self.RetinaOutput_cache[1:, :, :].clone()
        self.RetinaOutput_cache[-1,:,:]=output1


    
    def Lamina(self):
        # size=self.conv_params['GammaConv3d_1']['size']#GammaConv3d_1,GammaConv3d_2滑动窗口相同
        # index=[k%self.RetinaOutput.shape[2] for k in range(i-size+1,i+1)]
        # output=self.Gamma_Conv3d_forward(self.RetinaOutput_cache[:,:,index,:,:],self.GammaConv3d_1)-self.Gamma_Conv3d_forward(self.RetinaOutput_cache[:,:,index,:,:],self.GammaConv3d_2)
        
        # self.LaminaOutput=output
        size=self.conv_params['GammaConv3d_1']['size']#GammaConv3d_1,GammaConv3d_2滑动窗口相同
        index=[k for k in range(0,size)]
        output=self.Gamma_Conv3d_forward(self.RetinaOutput_cache[index,:,:],self.GammaConv3d_1)-self.Gamma_Conv3d_forward(self.RetinaOutput_cache[index,:,:],self.GammaConv3d_2)#[W,H]-[W,H]
        
        
        self.tempoutput11=output if self.count==15 else self.tempoutput11

        self.LaminaOutput=output
    
    def Medulla(self):
        size=self.conv_params['GammaConv3d_3']['size']#GammaConv3d_1,GammaConv3d_2滑动窗口相同
        
        ON=self.half_wave_rectifier(self.LaminaOutput)

        self.tempoutput12=ON if self.count==15 else self.tempoutput12
        self.MedullaOutput1_ON=ON
        

        self.OFF_cache[:-1,:,:]=self.OFF_cache[1:, :, :].clone()
        self.OFF_cache[-1,:,:]=self.half_wave_rectifier(-self.LaminaOutput)
        
        index=[k for k in range(0,size)]
        self.MedullaOutput2_OFFDELAY=self.Gamma_Conv3d_forward(self.OFF_cache[index,:,:],self.GammaConv3d_3)#[W,H]
    
    def Lobula(self):
        self.tempoutput=self.MedullaOutput1_ON if self.count==15 else self.tempoutput#debug
        self.tempoutput2=self.MedullaOutput2_OFFDELAY if self.count==15 else self.tempoutput2#debug
        self.count+=1#debug

        output=self.MedullaOutput1_ON*self.MedullaOutput2_OFFDELAY
        
        self.tempoutput3=output if self.count==15 else self.tempoutput3#debug

        output=self.Gauss_Conv2d_forward(output,self.GaussConv2d_2)#生成这个核时候已经做了减法

        self.tempoutput4=output if self.count==15 else self.tempoutput4#debug

        output=self.half_wave_rectifier(output)

        self.tempoutput5=output if self.count==15 else self.tempoutput5#debug

        """my stage"""
        #output=self.Gauss_Conv2d_forward(output,self.poolingConv2d)#普通的pooling不够用

        output=self.Log_Pooling_Conv2d_Forward(output,self.poolingConv2d)
        output=self.half_wave_rectifier(output)

        self.tempoutput7=output if self.count==15 else self.tempoutput7#debug

        

        output=output/torch.max(output)

        self.tempoutput8=output if self.count==15 else self.tempoutput8#debug
        self.LobulaOutputoutput=output
        
        # self.k=torch.max(output) if self.count==50 else self.k
        # self.tempoutput6=output if self.count==50 else self.tempoutput6

        

    
    def forward(self,frame):
        """
        #video_tensor: [B, C, T, H, W]
        frame: [H, W]
        """
        #Retina
        self.Retina(frame)
        #Lamina
        self.Lamina()
        #Medulla
        self.Medulla()
        #Lobula
        self.Lobula()

```
```python
import torch
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.image import AxesImage
import matplotlib
from PIL import Image 
import cv2
import math

# 设置图形在新窗口中显示
%matplotlib tk
# 中文字体配置
matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # Windows
matplotlib.rcParams['axes.unicode_minus'] = False

class STMDVisualizer:
    def __init__(self, fignames, modes, figsize=(8, 10), downsample_size=(16, 16)):
        """
        downsample_size=(H, W)
        """
        # 参数验证
        if len(fignames) != len(modes):
            raise ValueError("子图名称列表和模式列表长度必须一致")
        if not all(m in ['image','cell_activity', 'value'] for m in modes):
            raise ValueError("模式必须为 'cell_activity' 或 'value'")

        self.fignames = fignames
        self.modes = dict(zip(fignames, modes))
        self.downsample_size = downsample_size

        # 初始化缓存系统（新增关键代码）
        self.frame_caches = {
            name: None for name, mode in zip(fignames, modes)
            if mode == 'cell_activity'
        }
        
        # 创建坐标网格
        self._init_coordinate_grid()
        
        # 创建图形和坐标轴
        plt.ion()
        self._create_subplots(figsize)

        # 帧采集参数（用于后面用PIL的方法组成gif or mp4）
        self.frames = []        # 存储所有帧的RGB数据

    def _init_coordinate_grid(self):
        """初始化坐标网格系统"""
        x, y = torch.meshgrid(
            torch.arange(self.downsample_size[1]),#H
            torch.arange(self.downsample_size[0]),#W
            indexing='xy'
        )
        self.x_flat = x.T.flatten().numpy()
        self.y_flat = y.T.flatten().numpy()
        self.num_points = len(self.x_flat)

    def _create_subplots(self, figsize):
        """创建多模式子图布局"""
        subplot_size=(4,len(self.fignames)//4+1) if len(self.fignames) > 4 else (len(self.fignames), 1)
        self.fig, axes = plt.subplots(
            *subplot_size,
            figsize=figsize,
            squeeze=False
        )
        self.axes = {}
        self.plots = {}

        # 隐藏多余的子图
        for i in range(len(self.fignames)-1, 4 * (len(self.fignames)//4 + 1)):
            axes.flatten()[i].axis("off")
        
        for idx, (name, mode) in enumerate(zip(self.fignames, self.modes.values())):
            ax = axes[idx%4, idx//4]
            ax.set_title(f"{name} ({mode})", fontsize=10, pad=2)
            ax.axis('off')
            ax.set_aspect('equal')
            self.axes[name] = ax
            self.plots[name] = None

        plt.tight_layout(pad=3.0)
        self.fig.canvas.draw()

    def downsample_grayscale(self,gray_tensor: torch.Tensor, target_size: tuple) -> torch.Tensor:
        """
        处理单通道灰度数据
        输入形状：(H, W) 或 (1, H, W)
        输出形状：(target_H, target_W)
        """
        # 添加通道维度 -> (1, H, W)
        if gray_tensor.ndim == 2:
            tensor = gray_tensor.unsqueeze(0)
        else:
            tensor = gray_tensor

        # 添加batch维度 -> (1, 1, H, W)
        tensor = tensor.unsqueeze(0)

        # 执行降采样
        resized = F.interpolate(tensor, size=target_size,
                                mode='bilinear',
                                align_corners=False)

        # 恢复形状 (H, W)
        return resized.squeeze()
    def downsample_rgb(self,rgb_tensor: torch.Tensor, target_size: tuple) -> torch.Tensor:
        """
        处理3通道RGB数据
        输入形状：(H, W, 3) 或 (3, H, W)
        输出形状：(target_H, target_W, 3)
        """
        # 确保输入为4D Tensor (B, C, H, W)
        if tensor.dim() == 2:  # (H, W) -> (1, 1, H, W)
            tensor = tensor.unsqueeze(0).unsqueeze(0)
        elif tensor.dim() == 3:  # (C, H, W) -> (1, C, H, W)
            tensor = tensor.unsqueeze(0)
        
        # 执行降采样F.interpolate的输入维度是[B,C,H,W]因此上面要四个维度
        resized = F.interpolate(tensor, size=target_size, 
                            mode='bilinear', 
                            align_corners=False)
        
        # 恢复形状 (H, W, C)
        return resized.squeeze(0).permute(1, 2, 0)  # (C, H, W) -> (H, W, C)
    
    def _process_scatter_mode(self, tensor, mode,name):
        """处理散点图模式数据"""
        # 确保输入为4D Tensor (B, C, H, W)
        if tensor.dim() == 2:  # (H, W) -> (1, 1, H, W)
            tensor = tensor.unsqueeze(0).unsqueeze(0)
        elif tensor.dim() == 3:  # (C, H, W) -> (1, C, H, W)
            tensor = tensor.unsqueeze(0)
        
         # 执行降采样F.interpolate的输入维度是[B,C,H,W]因此上面要四个维度
        resized = F.interpolate(
            tensor.float(),
            size=self.downsample_size,
            mode='bilinear',
            align_corners=False
        )
        
        # 转换为numpy并展平
        data = resized.squeeze().cpu().numpy()
        data_flat = data.flatten(order='F')
        
        # 细胞活跃度处理
        if mode == 'cell_activity':
            data_flat = np.abs(data_flat - self.frame_caches.get(name)) if self.frame_caches.get(name) is not None else np.zeros_like(data_flat)
            self.frame_caches[name] = data_flat.copy()
        
        return data_flat
    
    def _process_image_mode(self, tensor):
        """处理图像模式数据"""
        # # 降采样
        # if tensor.ndim == 3:  # (C, H, W)
        #     tensor = tensor.squeeze(0)  # (B, C, H, W)
        # resized = F.interpolate(
        #     tensor.float(),
        #     size=self.downsample_size,
        #     mode='bilinear',
        #     align_corners=False
        # ).squeeze(0)
        
        # #转换为numpy并调整维度
        # data = resized.permute(1, 2, 0).cpu().numpy()  # (H, W, C)
        return tensor#不降采样了
    
    def update(self, frame_data):
        """
        更新所有子图数据（修复缓存系统）
        :param frame_data: 按fignames顺序的数据列表
        """
        #-------------------------------------------------imshow/scatter--------------------------------------------------
        for name, raw_data in zip(self.fignames, frame_data):
            ax = self.axes[name]
            mode = self.modes[name]
            plot=self.plots[name]
            
            try:
                # 模式分派处理
                if mode == 'image':
                    processed = self._process_image_mode(raw_data)
                else:
                    processed = self._process_scatter_mode(raw_data, mode,name)
                    # 新增颜色和大小计算逻辑
                    max_value = np.max(np.abs(processed))
                    max_value = max_value if max_value > 0 else 1.0         # 防止全零数据
                    # min_value = processed.min()
                    
                    # # 确保最大最小值有效
                    # if np.isclose(max_value, min_value):
                    #     if max_value == 0:
                    #         max_value = 1e-8  # 全零数据时设置极小正数，不然会导致scatter出错(min=0,max=0报错:max can not be equal to min)
                    #     else:
                    #         max_value = min_value + 1e-8

                    # 计算点的大小（确保零值不可见）
                    size = (processed / (max_value + 1e-8)) * 100  # 缩放因子设为100
                    size[size < 1e-3] = 0  # 零值设为不可见

            except Exception as e:
                raise ValueError(f"处理{name}数据失败: {str(e)}")
            # 首次初始化绘图元素
            if plot is None:
                if mode == 'image':
                    print(processed.shape)
                    self.plots[name] = ax.imshow(
                        processed,
                        cmap=None if processed.shape[-1] == 3 else 'gray',
                        origin='lower'
                    )
                else:
                    self.plots[name] = ax.scatter(
                        self.x_flat, 
                        self.y_flat,
                        s=size,  # 使用计算后的尺寸
                        c=processed,
                        cmap='bwr',  # 反向灰度colormap
                        alpha=0.8,
                        edgecolors='none',
                        vmin=-max_value,  # 固定最小值
                        vmax=max_value if max_value > 0 else 1  # 防止全零情况
                    )
                    # 添加颜色条
                    cbar = plt.colorbar(self.plots[name], ax=ax)
                    cbar.set_label('Value Scale')  # 可选：设置颜色条标签

            else:
                # 更新现有绘图元素
                if isinstance(plot, AxesImage):
                    plot.set_data(processed)
                    plot.set_clim(processed.min(), processed.max())

                else:
                    # 更新散点属性
                    plot.set_sizes(size)  # 更新点的大小
                    plot.set_array(processed)  # 更新颜色值
                    plot.set_clim(-max_value, max_value)  # 固定颜色范围
                    plot.set_cmap('bwr')  # 确保使用正确的colormap


                ax.draw_artist(plot)
            

        # 捕获当前帧为RGB数组
        self._capture_frame()

        self.fig.canvas.draw_idle()
        self.fig.canvas.flush_events()

    def _capture_frame(self):
        """将当前figure转为NHWC格式的numpy数组并存储"""
        # 强制渲染图形
        self.fig.canvas.draw()
        
        # 获取实际渲染尺寸
        w, h = self.fig.canvas.get_width_height()
        
        # 获取RGB缓冲区并重塑
        buffer = self.fig.canvas.tostring_rgb()
        img = np.frombuffer(buffer, dtype=np.uint8)
        
        # 正确重塑为 (height, width, 3)
        img = img.reshape((h, w, 3))
        
        # 转换为BGR格式并保存
        self.frames.append(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

    
    def save_animation(self, filename, fps=20, loop=0):
        """根据后缀保存为GIF或MP4动画"""
        if not self.frames:
            raise ValueError("没有可用的帧数据，请先调用update()方法")

        # 根据文件后缀选择保存格式
        if filename.lower().endswith('.gif'):
            # 保存为GIF格式
            pil_images = [Image.fromarray(cv2.cvtColor(f, cv2.COLOR_BGR2RGB)) 
                            for f in self.frames]
            pil_images[0].save(
                filename,
                save_all=True,
                append_images=pil_images[1:],
                duration=int(1000/fps),
                loop=loop,
                optimize=True,
                quality=95
            )
            print(f"GIF已保存至 {filename}，共 {len(pil_images)} 帧")

        elif filename.lower().endswith('.mp4'):
            # 保存为MP4格式
            h, w, _ = self.frames[1].shape
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4编解码器
            video_writer = cv2.VideoWriter(filename, fourcc, fps, (w, h))

            # 写入所有帧
            for frame in self.frames[1:]:
                video_writer.write(frame)
            
            video_writer.release()
            print(f"MP4已保存至 {filename}，共 {len(self.frames)} 帧，分辨率 {w}x{h}")

        else:
            raise ValueError("不支持的文件格式，仅支持 .gif 和 .mp4 后缀")

        # 统一清理资源
        if hasattr(cv2, 'VideoWriter'):
            cv2.destroyAllWindows()
            
    def close(self):
        """安全关闭可视化窗口"""
        plt.close(self.fig)
        plt.ioff()

```
```python
path="../Event_STMD/artifical_dataset/Translating_5_boxes.mp4"

video_tensor=video2tensor(path).squeeze().squeeze()#->[1,1,T,H,W]->[T,H,W]
global T
T,W,H=video_tensor.shape[0],video_tensor.shape[1],video_tensor.shape[2]
# 创建模型
conv_params = {
    'GammaConv3d_1': {'size': 20, 'tau': 1.0, 'n': 50},
    'GammaConv3d_2': {'size': 20, 'tau': 7.0, 'n': 50},
    'GammaConv3d_3': {'size': 20, 'tau': 8.0, 'n': 50},
    'GaussConv2d_1': {'sigma': 1.0, 'size': 3},
    'GaussConv2d_2': {'sigma': 1.5, 'size': 3},
    'GaussConv2d_3': {'sigma': 3.0, 'size': 3},
    'PoolingConv2d_1': {'size': 3, 'scaler': 1/9}
}
video_size=[video_tensor.shape[-2],video_tensor.shape[-1]]

model = STMD(video_size, conv_params)
visualizer = STMDVisualizer(
    ['RetinaOutput','LaminaOutput', 'MedullaOutput1_ON', 'MedullaOutput2_OFF','MedullaOutput2_OFFDELAY','LobulaOutputoutput'],
    modes=['image', 'value','value', 'value','value','value'],
    figsize=(8, 16),
    downsample_size=(24, 32)
)

temp1,temp2,temp3=[],[],[]

for i in tqdm(range(T), desc="Processing frames"):#frame=0:T-1
    # 处理每一帧
    frame=video_tensor[i,:,:]#frame=[W,H]=[480,640]

    model.forward(frame)
    
    frame_data = [
        model.RetinaOutput_cache[-1,:,:],        # 视频帧（H,W,3）
        model.LaminaOutput,                     # 运动检测（H,W）
        model.MedullaOutput1_ON,
        model.OFF_cache[-1,:,:],
        model.MedullaOutput2_OFFDELAY,      # Retina输出（H,W）
        model.LobulaOutputoutput
        
    ]
    visualizer.update(frame_data)
    #plt.pause(0.05)
    temp3.append(model.LobulaOutputoutput)
```

<div style="text-align: center;">
  <img src='/images/STMD2008/test.gif' alt='动态示例' style='width: 600px; height: auto;'>
  <p>GIF 动态演示效果</p>
</div>

<div style="text-align: center;">
  <video controls autoplay loop muted style='width: 600px; height: auto;'>
    <source src='/images/STMD2008/test.mp4' title="Title" type='video/mp4'>
    您的浏览器不支持视频播放。
  </video>
  <p>MP4 视频演示效果</p>
</div>

<video controls src= "https://github.com/DoubiCan/DoubiCan.github.io/blob/master/images/STMD2008/test.mp4" title="Title"></video>

<video
  id="video"
  src="@/images/STMD2008/test.mp4"
  autoplay
  muted
  controls
  controlsList="nodownload"
>您的浏览器不支持 video 标签。</video>

<iframe src="https://github.com/DoubiCan/DoubiCan.github.io/blob/master/images/STMD2008/test.mp4" width="640" height="360" frameborder="0" allowfullscreen></iframe>

---

<!-- <div style="text-align: center;">
  <img src='/images/Quasi-Newton_Method/logistics_optimization_Figure_1.png'>
  <img src='/images/Quasi-Newton_Method/logistics_optimization_Figure_2.png'>
  <p>物流中心选址优化问题用例</p>
</div> -->


